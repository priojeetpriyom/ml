{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4fdee2ce-5be4-41df-bf16-c917374ea7fc",
    "_uuid": "813c4df7b052f9ef5cc0f1cb856d68a284cdbb97"
   },
   "source": [
    "**Prepare data for training**\n",
    "\n",
    "My idea was the network would be trained to decide which factor is important, which is not, just feed all available features into the network\n",
    "\n",
    "\n",
    "* Only continuous and 1/0 data\n",
    "\n",
    "* Extract TITLE from NAME, idea from another Discussion\n",
    "\n",
    "* 1 for alive, -1 for dead\n",
    "\n",
    "* Create feature for the same Ticket number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "687"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import re\n",
    "# temp = \"Hoyt, Mr. Frederick Maxfield\"\n",
    "# print(re.search(' ([A-Za-z]+)\\.', temp))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "temp_df = pd.read_csv('./train.csv')\n",
    "# temp_df['Cabin'].isna().head()\n",
    "cnt=0\n",
    "for b in temp_df['Cabin'].isna():\n",
    "    cnt+= (b==True)\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "17dc7909-a07f-4f6b-a2e3-0d68fd61c91a",
    "_uuid": "7c0ef3a3ad39c3120f08f91304f6a1cbb85afc0d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pp/softwares/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:51: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>upperClass</th>\n",
       "      <th>middleClass</th>\n",
       "      <th>lowerClass</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Mrs</th>\n",
       "      <th>...</th>\n",
       "      <th>noCabin</th>\n",
       "      <th>Cherbourg</th>\n",
       "      <th>Queenstown</th>\n",
       "      <th>Southampton</th>\n",
       "      <th>noFamily</th>\n",
       "      <th>familySize</th>\n",
       "      <th>payingGreat</th>\n",
       "      <th>ticketSize</th>\n",
       "      <th>noTicketPartner</th>\n",
       "      <th>noAge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.091042</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.981001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.637586</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.266662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.258097</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.070022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.555348</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.972177</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.555348</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.085672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  SibSp  Parch      Fare  upperClass  middleClass  lowerClass  Mr  \\\n",
       "0  3.091042      1      0  1.981001           0            0           1   1   \n",
       "1  3.637586      1      0  4.266662           1            0           0   0   \n",
       "2  3.258097      0      0  2.070022           0            0           1   0   \n",
       "3  3.555348      1      0  3.972177           1            0           0   0   \n",
       "4  3.555348      0      0  2.085672           0            0           1   1   \n",
       "\n",
       "   Miss  Mrs  ...    noCabin  Cherbourg  Queenstown  Southampton  noFamily  \\\n",
       "0     0    0  ...          1          0           0            1         0   \n",
       "1     0    1  ...          0          1           0            0         0   \n",
       "2     1    0  ...          1          0           0            1         1   \n",
       "3     0    1  ...          0          0           0            1         0   \n",
       "4     0    0  ...          1          0           0            1         1   \n",
       "\n",
       "   familySize  payingGreat  ticketSize  noTicketPartner  noAge  \n",
       "0           2            0           1                1      0  \n",
       "1           2            1           2                0      0  \n",
       "2           1            0           1                1      0  \n",
       "3           2            1           2                0      0  \n",
       "4           1            0           1                1      0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "combine = [train_df, test_df]\n",
    "PassengerId = test_df['PassengerId']\n",
    "\n",
    "for dataset in combine:\n",
    "    #Pclass\n",
    "    dataset['upperClass'] = np.where(dataset['Pclass']==1,1,0)\n",
    "    dataset['middleClass'] = np.where(dataset['Pclass']==2,1,0)\n",
    "    dataset['lowerClass'] = np.where(dataset['Pclass']==3,1,0)\n",
    "    #Title\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    dataset['Mr'] = np.where(dataset['Title']=='Mr',1,0)\n",
    "    dataset['Miss'] = np.where(dataset['Title']=='Miss',1,0)\n",
    "    dataset['Mrs'] = np.where(dataset['Title']=='Mrs',1,0)\n",
    "    dataset['Master'] = np.where(dataset['Title']=='Master',1,0)\n",
    "    dataset['rareTitle'] = np.where(dataset['Title']=='Rare',1,0)\n",
    "    #Gender\n",
    "    dataset['female'] = np.where(dataset['Sex']=='female',1,0)\n",
    "    dataset['male'] = np.where(dataset['Sex']=='male',1,0)\n",
    "    #Cabin\n",
    "    dataset['CabinChar'] = dataset['Cabin'].str[:1]\n",
    "    dataset['A'] = np.where(dataset['CabinChar']=='A',1,0)\n",
    "    dataset['B'] = np.where(dataset['CabinChar']=='B',1,0)\n",
    "    dataset['C'] = np.where(dataset['CabinChar']=='C',1,0)\n",
    "    dataset['D'] = np.where(dataset['CabinChar']=='D',1,0)\n",
    "    dataset['E'] = np.where(dataset['CabinChar']=='E',1,0)\n",
    "    dataset['noCabin'] = np.where(dataset['Cabin'].isnull(),1,0)\n",
    "    #Embarked\n",
    "    dataset['Cherbourg'] = np.where(dataset['Embarked']=='C',1,0)\n",
    "    dataset['Queenstown'] = np.where(dataset['Embarked']=='Q',1,0)\n",
    "    dataset['Southampton'] = np.where(dataset['Embarked']=='S',1,0)\n",
    "    #No Family\n",
    "    dataset['noFamily'] = np.where(dataset['SibSp'] + dataset['Parch']==0,1,0)\n",
    "    dataset['familySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    \n",
    "    #Fare (filled below with log)\n",
    "    dataset['payingGreat'] = np.where(dataset['Fare']> dataset['Fare'].mean(), 1, 0)\n",
    "    \n",
    "    \n",
    "# train_df['Survived'] = train_df['Survived'].replace(0,-1)\n",
    "    \n",
    "# Average age on Title\n",
    "all_df = pd.concat([train_df, test_df])\n",
    "ageGroup = all_df.groupby('Title')['Age'].mean()\n",
    "# Ticket information\n",
    "ticketSize = all_df.groupby('Ticket')['PassengerId'].count()\n",
    "\n",
    "for dataset in combine:\n",
    "#     if('Survived' in dataset.columns and dataset['Survived'][0]==0):\n",
    "#         continue\n",
    "    # Ticket Size, Ticket Survived %\n",
    "    dataset['ticketSize'] = dataset['Ticket'].map(ticketSize)\n",
    "    dataset['noTicketPartner'] = np.where(dataset['ticketSize']==1,1,0)\n",
    "    # Null\n",
    "    dataset['noAge'] = np.where(dataset['Age'].isnull(),1,0)\n",
    "    dataset['Age'] = dataset['Age'].fillna(dataset['Title'].map(ageGroup))\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(dataset['Fare'].mean())\n",
    "    # Log\n",
    "    dataset['Age'] = np.where(dataset['Age'] < 1, 1, dataset['Age'])\n",
    "    dataset['Age'] = np.log(dataset['Age'])\n",
    "    dataset['Fare'] = np.where(dataset['Fare'] < 1, 1, dataset['Fare'])\n",
    "    dataset['Fare'] = np.log(dataset['Fare'])\n",
    "    \n",
    "\"\"\"\n",
    "Need to calculate the reference surived rate group by ticket\n",
    "Calculation need to exclude himself, otherwise the field is already have the survive data\n",
    "\"\"\"\n",
    "ticketInTrain = train_df.groupby('Ticket')['PassengerId'].count()\n",
    "ticketSurvived = train_df.groupby('Ticket')['Survived'].sum()/ train_df.groupby('Ticket')['PassengerId'].count()\n",
    "\n",
    "\n",
    "train_df['noTicketRef'] = np.where(train_df['Ticket'].map(ticketInTrain)==1,1,0)\n",
    "test_df['noTicketRef'] = np.where(test_df['Ticket'].map(ticketInTrain)>0,0,1)\n",
    "# train_df['ticketRef'] = np.where(train_df['noTicketRef']==1,0\n",
    "#         ,(train_df['Ticket'].map(ticketSurvived) * train_df['Ticket'].map(ticketInTrain) - train_df['Survived'])/(train_df['Ticket'].map(ticketInTrain) - 1))\n",
    "# test_df['ticketRef'] = np.where(test_df['noTicketRef']==1,0,test_df['Ticket'].map(ticketSurvived))\n",
    "\n",
    "train_result = train_df['Survived']\n",
    "train_df.to_csv('all.csv', index=False)\n",
    "#Drop\n",
    "train_df = train_df.drop(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Title', 'Ticket', 'Embarked', 'CabinChar', 'Cabin', 'noTicketRef'], axis=1)\n",
    "test_df = test_df.drop(['PassengerId', 'Pclass', 'Name', 'Title', 'Sex', 'Ticket', 'Embarked', 'CabinChar', 'Cabin', 'noTicketRef'], axis=1)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticketInTrain\n",
    "temp_df = pd.read_csv('./train.csv')\n",
    "# temp_df.groupby('Ticket')['Ticket'].count()\n",
    "# temp_df['Ticket'].map(ticketInTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "124304ac-43b4-4c09-9314-c2c7591aa2c3",
    "_uuid": "e6448286fe732e3ba2cf53d60fc9b9bca294caae"
   },
   "source": [
    "**Using Keras build neural network**\n",
    "\n",
    "-1st layer nodes = number of input * 2 (dropout 0.5)\n",
    "\n",
    "-2nd layer nodes = 1st layer nodes/2\n",
    "\n",
    "-Negative output means dead, Positive output means alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "from math import exp\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some data\n",
    "train_df = train_df.values\n",
    "train_result = train_result.values\n",
    "test_df = test_df.values\n",
    "\n",
    "x = train_df\n",
    "y = train_result\n",
    "z = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 29)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-9f00e67771b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# xx = list(list())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# yy = list()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# for i in y:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "# sum(y==0)\n",
    "# xx = list(list())\n",
    "# yy = list()\n",
    "# for i in y:\n",
    "#     if i==0:\n",
    "#         yy.append(i)\n",
    "#         xx.append(x[i])\n",
    "# x = np.array(xx)\n",
    "# y = np.array(yy)\n",
    "# sum(y==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pp/softwares/anaconda3/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build a neural network from the 1st layer to the last layer\n",
    "model = Sequential()\n",
    "model.add(Dense(units=58, input_dim=29))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units=106)) \n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Dense(units=256, activation=LeakyReLU(alpha=0.3))) \n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units=512, activation=LeakyReLU(alpha=0.3))) \n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Dense(units=256, activation=LeakyReLU(alpha=0.3))) \n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units=106, activation=LeakyReLU(alpha=0.3))) \n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units=58, activation=LeakyReLU(alpha=0.3))) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=29, activation=LeakyReLU(alpha=0.3))) \n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# choose loss function and optimizing method\n",
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=0.01)\n",
    "model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "3e98e093-acd0-4707-93db-37fe8f16211c",
    "_uuid": "67594ee5953332bc9fc370ad0bea3e01d651f845"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# training\n",
    "# print('Training -----------')\n",
    "# for step in range(10001):\n",
    "#     cost = model.train_on_batch(x, y)\n",
    "#     if step % 1000 == 0:\n",
    "#         print('step', step, 'train cost:', cost)\n",
    "        \n",
    "# print(\"----TRAINING FINISHED---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      " - 0s - loss: 0.2535 - acc: 0.5690\n",
      "Epoch 2/300\n",
      " - 0s - loss: 0.2452 - acc: 0.6105\n",
      "Epoch 3/300\n",
      " - 0s - loss: 0.2424 - acc: 0.6184\n",
      "Epoch 4/300\n",
      " - 0s - loss: 0.2405 - acc: 0.6173\n",
      "Epoch 5/300\n",
      " - 0s - loss: 0.2406 - acc: 0.6409\n",
      "Epoch 6/300\n",
      " - 0s - loss: 0.2240 - acc: 0.6453\n",
      "Epoch 7/300\n",
      " - 0s - loss: 0.2198 - acc: 0.6667\n",
      "Epoch 8/300\n",
      " - 0s - loss: 0.2056 - acc: 0.7003\n",
      "Epoch 9/300\n",
      " - 0s - loss: 0.2002 - acc: 0.7116\n",
      "Epoch 10/300\n",
      " - 0s - loss: 0.1983 - acc: 0.7071\n",
      "Epoch 11/300\n",
      " - 0s - loss: 0.1949 - acc: 0.7059\n",
      "Epoch 12/300\n",
      " - 0s - loss: 0.1822 - acc: 0.7407\n",
      "Epoch 13/300\n",
      " - 0s - loss: 0.1784 - acc: 0.7407\n",
      "Epoch 14/300\n",
      " - 0s - loss: 0.1730 - acc: 0.7508\n",
      "Epoch 15/300\n",
      " - 0s - loss: 0.1769 - acc: 0.7486\n",
      "Epoch 16/300\n",
      " - 0s - loss: 0.1719 - acc: 0.7464\n",
      "Epoch 17/300\n",
      " - 0s - loss: 0.1691 - acc: 0.7654\n",
      "Epoch 18/300\n",
      " - 0s - loss: 0.1687 - acc: 0.7553\n",
      "Epoch 19/300\n",
      " - 0s - loss: 0.1701 - acc: 0.7419\n",
      "Epoch 20/300\n",
      " - 0s - loss: 0.1602 - acc: 0.7722\n",
      "Epoch 21/300\n",
      " - 0s - loss: 0.1659 - acc: 0.7632\n",
      "Epoch 22/300\n",
      " - 0s - loss: 0.1645 - acc: 0.7609\n",
      "Epoch 23/300\n",
      " - 0s - loss: 0.1634 - acc: 0.7744\n",
      "Epoch 24/300\n",
      " - 0s - loss: 0.1577 - acc: 0.7834\n",
      "Epoch 25/300\n",
      " - 0s - loss: 0.1563 - acc: 0.7834\n",
      "Epoch 26/300\n",
      " - 0s - loss: 0.1581 - acc: 0.7733\n",
      "Epoch 27/300\n",
      " - 0s - loss: 0.1568 - acc: 0.7845\n",
      "Epoch 28/300\n",
      " - 0s - loss: 0.1667 - acc: 0.7598\n",
      "Epoch 29/300\n",
      " - 0s - loss: 0.1559 - acc: 0.7901\n",
      "Epoch 30/300\n",
      " - 0s - loss: 0.1596 - acc: 0.7722\n",
      "Epoch 31/300\n",
      " - 0s - loss: 0.1536 - acc: 0.7924\n",
      "Epoch 32/300\n",
      " - 0s - loss: 0.1471 - acc: 0.8025\n",
      "Epoch 33/300\n",
      " - 0s - loss: 0.1494 - acc: 0.7924\n",
      "Epoch 34/300\n",
      " - 0s - loss: 0.1464 - acc: 0.7924\n",
      "Epoch 35/300\n",
      " - 0s - loss: 0.1538 - acc: 0.7823\n",
      "Epoch 36/300\n",
      " - 0s - loss: 0.1478 - acc: 0.7935\n",
      "Epoch 37/300\n",
      " - 0s - loss: 0.1499 - acc: 0.7800\n",
      "Epoch 38/300\n",
      " - 0s - loss: 0.1504 - acc: 0.8081\n",
      "Epoch 39/300\n",
      " - 0s - loss: 0.1464 - acc: 0.8002\n",
      "Epoch 40/300\n",
      " - 0s - loss: 0.1469 - acc: 0.7912\n",
      "Epoch 41/300\n",
      " - 0s - loss: 0.1466 - acc: 0.7980\n",
      "Epoch 42/300\n",
      " - 0s - loss: 0.1450 - acc: 0.8047\n",
      "Epoch 43/300\n",
      " - 0s - loss: 0.1511 - acc: 0.8002\n",
      "Epoch 44/300\n",
      " - 0s - loss: 0.1493 - acc: 0.7890\n",
      "Epoch 45/300\n",
      " - 0s - loss: 0.1525 - acc: 0.7811\n",
      "Epoch 46/300\n",
      " - 0s - loss: 0.1409 - acc: 0.8070\n",
      "Epoch 47/300\n",
      " - 0s - loss: 0.1459 - acc: 0.7957\n",
      "Epoch 48/300\n",
      " - 0s - loss: 0.1443 - acc: 0.8036\n",
      "Epoch 49/300\n",
      " - 0s - loss: 0.1436 - acc: 0.7901\n",
      "Epoch 50/300\n",
      " - 0s - loss: 0.1424 - acc: 0.8002\n",
      "Epoch 51/300\n",
      " - 0s - loss: 0.1443 - acc: 0.8058\n",
      "Epoch 52/300\n",
      " - 0s - loss: 0.1420 - acc: 0.7980\n",
      "Epoch 53/300\n",
      " - 0s - loss: 0.1447 - acc: 0.8002\n",
      "Epoch 54/300\n",
      " - 0s - loss: 0.1415 - acc: 0.8047\n",
      "Epoch 55/300\n",
      " - 0s - loss: 0.1440 - acc: 0.8058\n",
      "Epoch 56/300\n",
      " - 0s - loss: 0.1474 - acc: 0.7912\n",
      "Epoch 57/300\n",
      " - 0s - loss: 0.1518 - acc: 0.7901\n",
      "Epoch 58/300\n",
      " - 0s - loss: 0.1418 - acc: 0.8103\n",
      "Epoch 59/300\n",
      " - 0s - loss: 0.1407 - acc: 0.8025\n",
      "Epoch 60/300\n",
      " - 0s - loss: 0.1376 - acc: 0.8081\n",
      "Epoch 61/300\n",
      " - 0s - loss: 0.1423 - acc: 0.8036\n",
      "Epoch 62/300\n",
      " - 0s - loss: 0.1462 - acc: 0.7901\n",
      "Epoch 63/300\n",
      " - 0s - loss: 0.1378 - acc: 0.8081\n",
      "Epoch 64/300\n",
      " - 0s - loss: 0.1396 - acc: 0.8058\n",
      "Epoch 65/300\n",
      " - 0s - loss: 0.1358 - acc: 0.8193\n",
      "Epoch 66/300\n",
      " - 0s - loss: 0.1381 - acc: 0.8137\n",
      "Epoch 67/300\n",
      " - 0s - loss: 0.1488 - acc: 0.8114\n",
      "Epoch 68/300\n",
      " - 0s - loss: 0.1437 - acc: 0.7924\n",
      "Epoch 69/300\n",
      " - 0s - loss: 0.1469 - acc: 0.7912\n",
      "Epoch 70/300\n",
      " - 0s - loss: 0.1385 - acc: 0.8092\n",
      "Epoch 71/300\n",
      " - 0s - loss: 0.1385 - acc: 0.8081\n",
      "Epoch 72/300\n",
      " - 0s - loss: 0.1417 - acc: 0.7991\n",
      "Epoch 73/300\n",
      " - 0s - loss: 0.1384 - acc: 0.8081\n",
      "Epoch 74/300\n",
      " - 0s - loss: 0.1427 - acc: 0.8103\n",
      "Epoch 75/300\n",
      " - 0s - loss: 0.1376 - acc: 0.8204\n",
      "Epoch 76/300\n",
      " - 0s - loss: 0.1367 - acc: 0.8081\n",
      "Epoch 77/300\n",
      " - 0s - loss: 0.1372 - acc: 0.8249\n",
      "Epoch 78/300\n",
      " - 0s - loss: 0.1377 - acc: 0.8114\n",
      "Epoch 79/300\n",
      " - 0s - loss: 0.1354 - acc: 0.8126\n",
      "Epoch 80/300\n",
      " - 0s - loss: 0.1339 - acc: 0.8283\n",
      "Epoch 81/300\n",
      " - 0s - loss: 0.1415 - acc: 0.8070\n",
      "Epoch 82/300\n",
      " - 0s - loss: 0.1334 - acc: 0.8193\n",
      "Epoch 83/300\n",
      " - 0s - loss: 0.1430 - acc: 0.8148\n",
      "Epoch 84/300\n",
      " - 0s - loss: 0.1388 - acc: 0.8238\n",
      "Epoch 85/300\n",
      " - 0s - loss: 0.1416 - acc: 0.8081\n",
      "Epoch 86/300\n",
      " - 0s - loss: 0.1377 - acc: 0.8114\n",
      "Epoch 87/300\n",
      " - 0s - loss: 0.1512 - acc: 0.7935\n",
      "Epoch 88/300\n",
      " - 0s - loss: 0.1353 - acc: 0.8204\n",
      "Epoch 89/300\n",
      " - 0s - loss: 0.1319 - acc: 0.8238\n",
      "Epoch 90/300\n",
      " - 0s - loss: 0.1366 - acc: 0.8103\n",
      "Epoch 91/300\n",
      " - 0s - loss: 0.1388 - acc: 0.8103\n",
      "Epoch 92/300\n",
      " - 0s - loss: 0.1344 - acc: 0.8126\n",
      "Epoch 93/300\n",
      " - 0s - loss: 0.1315 - acc: 0.8126\n",
      "Epoch 94/300\n",
      " - 0s - loss: 0.1363 - acc: 0.8058\n",
      "Epoch 95/300\n",
      " - 0s - loss: 0.1372 - acc: 0.8092\n",
      "Epoch 96/300\n",
      " - 0s - loss: 0.1394 - acc: 0.8036\n",
      "Epoch 97/300\n",
      " - 0s - loss: 0.1405 - acc: 0.8058\n",
      "Epoch 98/300\n",
      " - 0s - loss: 0.1297 - acc: 0.8204\n",
      "Epoch 99/300\n",
      " - 0s - loss: 0.1363 - acc: 0.8227\n",
      "Epoch 100/300\n",
      " - 0s - loss: 0.1355 - acc: 0.8249\n",
      "Epoch 101/300\n",
      " - 0s - loss: 0.1357 - acc: 0.8159\n",
      "Epoch 102/300\n",
      " - 0s - loss: 0.1388 - acc: 0.8114\n",
      "Epoch 103/300\n",
      " - 0s - loss: 0.1377 - acc: 0.8171\n",
      "Epoch 104/300\n",
      " - 0s - loss: 0.1357 - acc: 0.8126\n",
      "Epoch 105/300\n",
      " - 0s - loss: 0.1344 - acc: 0.8137\n",
      "Epoch 106/300\n",
      " - 0s - loss: 0.1301 - acc: 0.8260\n",
      "Epoch 107/300\n",
      " - 0s - loss: 0.1357 - acc: 0.8137\n",
      "Epoch 108/300\n",
      " - 0s - loss: 0.1364 - acc: 0.8182\n",
      "Epoch 109/300\n",
      " - 0s - loss: 0.1367 - acc: 0.8193\n",
      "Epoch 110/300\n",
      " - 0s - loss: 0.1314 - acc: 0.8294\n",
      "Epoch 111/300\n",
      " - 0s - loss: 0.1325 - acc: 0.8249\n",
      "Epoch 112/300\n",
      " - 0s - loss: 0.1310 - acc: 0.8260\n",
      "Epoch 113/300\n",
      " - 0s - loss: 0.1328 - acc: 0.8171\n",
      "Epoch 114/300\n",
      " - 0s - loss: 0.1316 - acc: 0.8171\n",
      "Epoch 115/300\n",
      " - 0s - loss: 0.1410 - acc: 0.8070\n",
      "Epoch 116/300\n",
      " - 0s - loss: 0.1326 - acc: 0.8272\n",
      "Epoch 117/300\n",
      " - 0s - loss: 0.1337 - acc: 0.8272\n",
      "Epoch 118/300\n",
      " - 0s - loss: 0.1296 - acc: 0.8373\n",
      "Epoch 119/300\n",
      " - 0s - loss: 0.1308 - acc: 0.8182\n",
      "Epoch 120/300\n",
      " - 0s - loss: 0.1296 - acc: 0.8260\n",
      "Epoch 121/300\n",
      " - 0s - loss: 0.1440 - acc: 0.8114\n",
      "Epoch 122/300\n",
      " - 0s - loss: 0.1337 - acc: 0.8260\n",
      "Epoch 123/300\n",
      " - 0s - loss: 0.1307 - acc: 0.8238\n",
      "Epoch 124/300\n",
      " - 0s - loss: 0.1335 - acc: 0.8171\n",
      "Epoch 125/300\n",
      " - 0s - loss: 0.1383 - acc: 0.8002\n",
      "Epoch 126/300\n",
      " - 0s - loss: 0.1362 - acc: 0.8171\n",
      "Epoch 127/300\n",
      " - 0s - loss: 0.1371 - acc: 0.8114\n",
      "Epoch 128/300\n",
      " - 0s - loss: 0.1268 - acc: 0.8328\n",
      "Epoch 129/300\n",
      " - 0s - loss: 0.1296 - acc: 0.8272\n",
      "Epoch 130/300\n",
      " - 0s - loss: 0.1357 - acc: 0.8215\n",
      "Epoch 131/300\n",
      " - 0s - loss: 0.1308 - acc: 0.8294\n",
      "Epoch 132/300\n",
      " - 0s - loss: 0.1323 - acc: 0.8182\n",
      "Epoch 133/300\n",
      " - 0s - loss: 0.1316 - acc: 0.8272\n",
      "Epoch 134/300\n",
      " - 0s - loss: 0.1310 - acc: 0.8215\n",
      "Epoch 135/300\n",
      " - 0s - loss: 0.1276 - acc: 0.8283\n",
      "Epoch 136/300\n",
      " - 0s - loss: 0.1301 - acc: 0.8350\n",
      "Epoch 137/300\n",
      " - 0s - loss: 0.1290 - acc: 0.8283\n",
      "Epoch 138/300\n",
      " - 0s - loss: 0.1315 - acc: 0.8316\n",
      "Epoch 139/300\n",
      " - 0s - loss: 0.1372 - acc: 0.8159\n",
      "Epoch 140/300\n",
      " - 0s - loss: 0.1314 - acc: 0.8182\n",
      "Epoch 141/300\n",
      " - 0s - loss: 0.1303 - acc: 0.8193\n",
      "Epoch 142/300\n",
      " - 0s - loss: 0.1297 - acc: 0.8260\n",
      "Epoch 143/300\n",
      " - 0s - loss: 0.1272 - acc: 0.8249\n",
      "Epoch 144/300\n",
      " - 0s - loss: 0.1283 - acc: 0.8260\n",
      "Epoch 145/300\n",
      " - 0s - loss: 0.1284 - acc: 0.8283\n",
      "Epoch 146/300\n",
      " - 0s - loss: 0.1357 - acc: 0.8227\n",
      "Epoch 147/300\n",
      " - 0s - loss: 0.1310 - acc: 0.8204\n",
      "Epoch 148/300\n",
      " - 0s - loss: 0.1320 - acc: 0.8137\n",
      "Epoch 149/300\n",
      " - 0s - loss: 0.1229 - acc: 0.8305\n",
      "Epoch 150/300\n",
      " - 0s - loss: 0.1298 - acc: 0.8227\n",
      "Epoch 151/300\n",
      " - 0s - loss: 0.1272 - acc: 0.8283\n",
      "Epoch 152/300\n",
      " - 0s - loss: 0.1298 - acc: 0.8182\n",
      "Epoch 153/300\n",
      " - 0s - loss: 0.1277 - acc: 0.8305\n",
      "Epoch 154/300\n",
      " - 0s - loss: 0.1321 - acc: 0.8260\n",
      "Epoch 155/300\n",
      " - 0s - loss: 0.1289 - acc: 0.8272\n",
      "Epoch 156/300\n",
      " - 0s - loss: 0.1305 - acc: 0.8305\n",
      "Epoch 157/300\n",
      " - 0s - loss: 0.1262 - acc: 0.8339\n",
      "Epoch 158/300\n",
      " - 0s - loss: 0.1320 - acc: 0.8148\n",
      "Epoch 159/300\n",
      " - 0s - loss: 0.1330 - acc: 0.8215\n",
      "Epoch 160/300\n",
      " - 0s - loss: 0.1387 - acc: 0.8148\n",
      "Epoch 161/300\n",
      " - 0s - loss: 0.1279 - acc: 0.8283\n",
      "Epoch 162/300\n",
      " - 0s - loss: 0.1272 - acc: 0.8339\n",
      "Epoch 163/300\n",
      " - 0s - loss: 0.1279 - acc: 0.8260\n",
      "Epoch 164/300\n",
      " - 0s - loss: 0.1275 - acc: 0.8249\n",
      "Epoch 165/300\n",
      " - 0s - loss: 0.1289 - acc: 0.8249\n",
      "Epoch 166/300\n",
      " - 0s - loss: 0.1265 - acc: 0.8305\n",
      "Epoch 167/300\n",
      " - 0s - loss: 0.1262 - acc: 0.8215\n",
      "Epoch 168/300\n",
      " - 0s - loss: 0.1273 - acc: 0.8272\n",
      "Epoch 169/300\n",
      " - 0s - loss: 0.1277 - acc: 0.8316\n",
      "Epoch 170/300\n",
      " - 0s - loss: 0.1277 - acc: 0.8339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/300\n",
      " - 0s - loss: 0.1270 - acc: 0.8328\n",
      "Epoch 172/300\n",
      " - 0s - loss: 0.1264 - acc: 0.8429\n",
      "Epoch 173/300\n",
      " - 0s - loss: 0.1286 - acc: 0.8215\n",
      "Epoch 174/300\n",
      " - 0s - loss: 0.1287 - acc: 0.8316\n",
      "Epoch 175/300\n",
      " - 0s - loss: 0.1231 - acc: 0.8373\n",
      "Epoch 176/300\n",
      " - 0s - loss: 0.1328 - acc: 0.8058\n",
      "Epoch 177/300\n",
      " - 0s - loss: 0.1285 - acc: 0.8238\n",
      "Epoch 178/300\n",
      " - 0s - loss: 0.1255 - acc: 0.8215\n",
      "Epoch 179/300\n",
      " - 0s - loss: 0.1272 - acc: 0.8350\n",
      "Epoch 180/300\n",
      " - 0s - loss: 0.1278 - acc: 0.8294\n",
      "Epoch 181/300\n",
      " - 0s - loss: 0.1367 - acc: 0.8283\n",
      "Epoch 182/300\n",
      " - 0s - loss: 0.1366 - acc: 0.8148\n",
      "Epoch 183/300\n",
      " - 0s - loss: 0.1261 - acc: 0.8339\n",
      "Epoch 184/300\n",
      " - 0s - loss: 0.1258 - acc: 0.8272\n",
      "Epoch 185/300\n",
      " - 0s - loss: 0.1278 - acc: 0.8249\n",
      "Epoch 186/300\n",
      " - 0s - loss: 0.1226 - acc: 0.8451\n",
      "Epoch 187/300\n",
      " - 0s - loss: 0.1279 - acc: 0.8305\n",
      "Epoch 188/300\n",
      " - 0s - loss: 0.1292 - acc: 0.8272\n",
      "Epoch 189/300\n",
      " - 0s - loss: 0.1245 - acc: 0.8328\n",
      "Epoch 190/300\n",
      " - 0s - loss: 0.1276 - acc: 0.8182\n",
      "Epoch 191/300\n",
      " - 0s - loss: 0.1258 - acc: 0.8294\n",
      "Epoch 192/300\n",
      " - 0s - loss: 0.1253 - acc: 0.8395\n",
      "Epoch 193/300\n",
      " - 0s - loss: 0.1240 - acc: 0.8260\n",
      "Epoch 194/300\n",
      " - 0s - loss: 0.1218 - acc: 0.8395\n",
      "Epoch 195/300\n",
      " - 0s - loss: 0.1272 - acc: 0.8204\n",
      "Epoch 196/300\n",
      " - 0s - loss: 0.1259 - acc: 0.8305\n",
      "Epoch 197/300\n",
      " - 0s - loss: 0.1231 - acc: 0.8283\n",
      "Epoch 198/300\n",
      " - 0s - loss: 0.1251 - acc: 0.8440\n",
      "Epoch 199/300\n",
      " - 0s - loss: 0.1259 - acc: 0.8339\n",
      "Epoch 200/300\n",
      " - 0s - loss: 0.1228 - acc: 0.8395\n",
      "Epoch 201/300\n",
      " - 0s - loss: 0.1248 - acc: 0.8406\n",
      "Epoch 202/300\n",
      " - 0s - loss: 0.1224 - acc: 0.8384\n",
      "Epoch 203/300\n",
      " - 0s - loss: 0.1259 - acc: 0.8294\n",
      "Epoch 204/300\n",
      " - 0s - loss: 0.1226 - acc: 0.8384\n",
      "Epoch 205/300\n",
      " - 0s - loss: 0.1249 - acc: 0.8339\n",
      "Epoch 206/300\n",
      " - 0s - loss: 0.1278 - acc: 0.8305\n",
      "Epoch 207/300\n",
      " - 0s - loss: 0.1260 - acc: 0.8373\n",
      "Epoch 208/300\n",
      " - 0s - loss: 0.1223 - acc: 0.8350\n",
      "Epoch 209/300\n",
      " - 0s - loss: 0.1221 - acc: 0.8395\n",
      "Epoch 210/300\n",
      " - 0s - loss: 0.1233 - acc: 0.8328\n",
      "Epoch 211/300\n",
      " - 0s - loss: 0.1275 - acc: 0.8283\n",
      "Epoch 212/300\n",
      " - 0s - loss: 0.1247 - acc: 0.8384\n",
      "Epoch 213/300\n",
      " - 0s - loss: 0.1237 - acc: 0.8350\n",
      "Epoch 214/300\n",
      " - 0s - loss: 0.1213 - acc: 0.8339\n",
      "Epoch 215/300\n",
      " - 0s - loss: 0.1263 - acc: 0.8328\n",
      "Epoch 216/300\n",
      " - 0s - loss: 0.1230 - acc: 0.8316\n",
      "Epoch 217/300\n",
      " - 0s - loss: 0.1303 - acc: 0.8238\n",
      "Epoch 218/300\n",
      " - 0s - loss: 0.1261 - acc: 0.8260\n",
      "Epoch 219/300\n",
      " - 0s - loss: 0.1232 - acc: 0.8429\n",
      "Epoch 220/300\n",
      " - 0s - loss: 0.1248 - acc: 0.8272\n",
      "Epoch 221/300\n",
      " - 0s - loss: 0.1235 - acc: 0.8350\n",
      "Epoch 222/300\n",
      " - 0s - loss: 0.1247 - acc: 0.8339\n",
      "Epoch 223/300\n",
      " - 0s - loss: 0.1288 - acc: 0.8294\n",
      "Epoch 224/300\n",
      " - 0s - loss: 0.1289 - acc: 0.8215\n",
      "Epoch 225/300\n",
      " - 0s - loss: 0.1219 - acc: 0.8440\n",
      "Epoch 226/300\n",
      " - 0s - loss: 0.1249 - acc: 0.8328\n",
      "Epoch 227/300\n",
      " - 0s - loss: 0.1278 - acc: 0.8283\n",
      "Epoch 228/300\n",
      " - 0s - loss: 0.1378 - acc: 0.8126\n",
      "Epoch 229/300\n",
      " - 0s - loss: 0.1251 - acc: 0.8316\n",
      "Epoch 230/300\n",
      " - 0s - loss: 0.1262 - acc: 0.8328\n",
      "Epoch 231/300\n",
      " - 0s - loss: 0.1311 - acc: 0.8227\n",
      "Epoch 232/300\n",
      " - 0s - loss: 0.1262 - acc: 0.8316\n",
      "Epoch 233/300\n",
      " - 0s - loss: 0.1223 - acc: 0.8316\n",
      "Epoch 234/300\n",
      " - 0s - loss: 0.1220 - acc: 0.8350\n",
      "Epoch 235/300\n",
      " - 0s - loss: 0.1250 - acc: 0.8204\n",
      "Epoch 236/300\n",
      " - 0s - loss: 0.1247 - acc: 0.8395\n",
      "Epoch 237/300\n",
      " - 0s - loss: 0.1216 - acc: 0.8406\n",
      "Epoch 238/300\n",
      " - 0s - loss: 0.1223 - acc: 0.8395\n",
      "Epoch 239/300\n",
      " - 0s - loss: 0.1228 - acc: 0.8316\n",
      "Epoch 240/300\n",
      " - 0s - loss: 0.1230 - acc: 0.8361\n",
      "Epoch 241/300\n",
      " - 0s - loss: 0.1190 - acc: 0.8418\n",
      "Epoch 242/300\n",
      " - 0s - loss: 0.1215 - acc: 0.8474\n",
      "Epoch 243/300\n",
      " - 0s - loss: 0.1612 - acc: 0.7811\n",
      "Epoch 244/300\n",
      " - 0s - loss: 0.1304 - acc: 0.8159\n",
      "Epoch 245/300\n",
      " - 0s - loss: 0.1435 - acc: 0.8070\n",
      "Epoch 246/300\n",
      " - 0s - loss: 0.1220 - acc: 0.8339\n",
      "Epoch 247/300\n",
      " - 0s - loss: 0.1253 - acc: 0.8249\n",
      "Epoch 248/300\n",
      " - 0s - loss: 0.1245 - acc: 0.8328\n",
      "Epoch 249/300\n",
      " - 0s - loss: 0.1282 - acc: 0.8294\n",
      "Epoch 250/300\n",
      " - 0s - loss: 0.1236 - acc: 0.8249\n",
      "Epoch 251/300\n",
      " - 0s - loss: 0.1235 - acc: 0.8373\n",
      "Epoch 252/300\n",
      " - 0s - loss: 0.1235 - acc: 0.8339\n",
      "Epoch 253/300\n",
      " - 0s - loss: 0.1219 - acc: 0.8429\n",
      "Epoch 254/300\n",
      " - 0s - loss: 0.1230 - acc: 0.8294\n",
      "Epoch 255/300\n",
      " - 0s - loss: 0.1256 - acc: 0.8350\n",
      "Epoch 256/300\n",
      " - 0s - loss: 0.1346 - acc: 0.8249\n",
      "Epoch 257/300\n",
      " - 0s - loss: 0.1302 - acc: 0.8350\n",
      "Epoch 258/300\n",
      " - 0s - loss: 0.1232 - acc: 0.8395\n",
      "Epoch 259/300\n",
      " - 0s - loss: 0.1305 - acc: 0.8182\n",
      "Epoch 260/300\n",
      " - 0s - loss: 0.1220 - acc: 0.8395\n",
      "Epoch 261/300\n",
      " - 0s - loss: 0.1247 - acc: 0.8249\n",
      "Epoch 262/300\n",
      " - 0s - loss: 0.1324 - acc: 0.8148\n",
      "Epoch 263/300\n",
      " - 0s - loss: 0.1243 - acc: 0.8316\n",
      "Epoch 264/300\n",
      " - 0s - loss: 0.1247 - acc: 0.8328\n",
      "Epoch 265/300\n",
      " - 0s - loss: 0.1295 - acc: 0.8249\n",
      "Epoch 266/300\n",
      " - 0s - loss: 0.1233 - acc: 0.8395\n",
      "Epoch 267/300\n",
      " - 0s - loss: 0.1250 - acc: 0.8272\n",
      "Epoch 268/300\n",
      " - 0s - loss: 0.1245 - acc: 0.8373\n",
      "Epoch 269/300\n",
      " - 0s - loss: 0.1223 - acc: 0.8395\n",
      "Epoch 270/300\n",
      " - 0s - loss: 0.1236 - acc: 0.8395\n",
      "Epoch 271/300\n",
      " - 0s - loss: 0.1232 - acc: 0.8328\n",
      "Epoch 272/300\n",
      " - 0s - loss: 0.1215 - acc: 0.8373\n",
      "Epoch 273/300\n",
      " - 0s - loss: 0.1245 - acc: 0.8361\n",
      "Epoch 274/300\n",
      " - 0s - loss: 0.1219 - acc: 0.8406\n",
      "Epoch 275/300\n",
      " - 0s - loss: 0.1358 - acc: 0.8114\n",
      "Epoch 276/300\n",
      " - 0s - loss: 0.1232 - acc: 0.8429\n",
      "Epoch 277/300\n",
      " - 0s - loss: 0.1239 - acc: 0.8384\n",
      "Epoch 278/300\n",
      " - 0s - loss: 0.1231 - acc: 0.8361\n",
      "Epoch 279/300\n",
      " - 0s - loss: 0.1236 - acc: 0.8328\n",
      "Epoch 280/300\n",
      " - 0s - loss: 0.1233 - acc: 0.8272\n",
      "Epoch 281/300\n",
      " - 0s - loss: 0.1213 - acc: 0.8294\n",
      "Epoch 282/300\n",
      " - 0s - loss: 0.1217 - acc: 0.8395\n",
      "Epoch 283/300\n",
      " - 0s - loss: 0.1259 - acc: 0.8238\n",
      "Epoch 284/300\n",
      " - 0s - loss: 0.1195 - acc: 0.8373\n",
      "Epoch 285/300\n",
      " - 0s - loss: 0.1229 - acc: 0.8305\n",
      "Epoch 286/300\n",
      " - 0s - loss: 0.1251 - acc: 0.8305\n",
      "Epoch 287/300\n",
      " - 0s - loss: 0.1228 - acc: 0.8395\n",
      "Epoch 288/300\n",
      " - 0s - loss: 0.1202 - acc: 0.8373\n",
      "Epoch 289/300\n",
      " - 0s - loss: 0.1222 - acc: 0.8384\n",
      "Epoch 290/300\n",
      " - 0s - loss: 0.1212 - acc: 0.8406\n",
      "Epoch 291/300\n",
      " - 0s - loss: 0.1211 - acc: 0.8429\n",
      "Epoch 292/300\n",
      " - 0s - loss: 0.1198 - acc: 0.8440\n",
      "Epoch 293/300\n",
      " - 0s - loss: 0.1244 - acc: 0.8305\n",
      "Epoch 294/300\n",
      " - 0s - loss: 0.1226 - acc: 0.8305\n",
      "Epoch 295/300\n",
      " - 0s - loss: 0.1227 - acc: 0.8395\n",
      "Epoch 296/300\n",
      " - 0s - loss: 0.1223 - acc: 0.8418\n",
      "Epoch 297/300\n",
      " - 0s - loss: 0.1204 - acc: 0.8418\n",
      "Epoch 298/300\n",
      " - 0s - loss: 0.1296 - acc: 0.8283\n",
      "Epoch 299/300\n",
      " - 0s - loss: 0.1209 - acc: 0.8406\n",
      "Epoch 300/300\n",
      " - 0s - loss: 0.1251 - acc: 0.8316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb4b107d4a8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=int(len(x)/10),\n",
    "          epochs=300,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.754496192938231\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# predict\n",
    "test_predict = model.predict(z)\n",
    "# exp(test_predict.ravel()).mean()\n",
    "# temp = list(test_predict.flatten())\n",
    "# exp(temp).mean()\n",
    "sum=0\n",
    "for x in test_predict:\n",
    "    sum+= exp(x)\n",
    "print(sum/ test_predict.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "5cb27b58-9c3f-4ae1-bb06-79f62e089bc3",
    "_uuid": "b0ac9d0fe85bbe5913fb3da41f5f88c3f4c4288a"
   },
   "outputs": [],
   "source": [
    "# Generate Submission File\n",
    "test_predict = np.where(test_predict>.5,1,0)\n",
    "NNSubmission = pd.DataFrame({ 'PassengerId': PassengerId,\n",
    "                            'Survived': test_predict.ravel() })\n",
    "NNSubmission.to_csv(\"NNSubmission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
